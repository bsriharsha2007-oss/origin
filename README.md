# SwarmForge - Scalable Multi-Agent AI Framework

A production-ready framework for building scalable multi-agent AI systems with LLM coordination, parallel/sequential execution, tool integration, memory management, and output evaluation.

Web App Quick Start

- Run the embedded FastAPI web UI: `python webserver.py`
- Open the web UI in your browser at `http://127.0.0.1:8000`
- If your browser rejects `localhost:8000`, use `http://127.0.0.1:8000` (copy-paste the exact URL).

## ğŸš€ Features

- **Multi-Agent Orchestration**: Coordinate multiple specialized AI agents
- **Parallel & Sequential Execution**: Choose between execution modes for optimal performance
- **LangGraph Integration**: Built on LangChain's LangGraph for reliable workflows
- **Memory Management**: Dual-tier memory (short-term & long-term) with categorization
- **Tool Integration**: Web search, code execution, file operations, data analysis
- **Evaluation Engine**: Automatic output evaluation and quality scoring
- **Hierarchical Coordination**: Support for coordinator-worker patterns
- **Event Logging**: Comprehensive execution tracking and analytics

## ğŸ“‹ Prerequisites

- Python 3.10+
- API Keys (at least one):
  - OpenAI API key (for GPT-4/3.5-turbo) OR
  - Groq API key (free tier available)
- Optional: Tavily API key for web search capabilities

## ğŸ› ï¸ Installation

### 1. Clone and Setup
```bash
cd swarmforge
python -m venv venv
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure Environment
```bash
# Copy the example environment file
cp .env.example .env

# Edit .env with your API keys
# Required: OPENAI_API_KEY or GROQ_API_KEY
# Optional: TAVILY_API_KEY for web search
```

## ğŸƒ Quick Start

### Run the Interactive Demo
```bash
python main.py
```

This will launch an interactive menu where you can:
1. **Basic Workflow** - Test LangGraph with memory and evaluation
2. **Agent Pool** - See parallel/sequential agent execution
3. **Full Workflow** - End-to-end multi-agent orchestration
4. Exit

### Example: Create Your Own Swarm

```python
from langchain_openai import ChatOpenAI
from agents import AgentConfig, AgentRole, ExecutionMode, SwarmOrchestrator
from graph import SwarmGraph

# Initialize LLM
llm = ChatOpenAI(model="gpt-3.5-turbo")

# Create the swarm orchestrator
orchestrator = SwarmOrchestrator(llm)
pool = orchestrator.create_pool("my_team")

# Add agents
pool.add_agent(AgentConfig(
    name="researcher",
    role=AgentRole.RESEARCHER,
    tools=["web_search"]
))

pool.add_agent(AgentConfig(
    name="analyzer",
    role=AgentRole.ANALYZER,
    tools=["data_analysis"]
))

# Execute in parallel
pool.set_execution_mode(ExecutionMode.PARALLEL)
import asyncio
results = asyncio.run(pool.execute("Analyze AI trends"))
```

## ğŸ“ Project Structure

```
swarmforge/
â”œâ”€â”€ main.py              # Entry point and demos
â”œâ”€â”€ agents.py            # Agent orchestration (sequential/parallel/hierarchical)
â”œâ”€â”€ graph.py             # LangGraph workflows with memory & evaluation
â”œâ”€â”€ tools.py             # Tool definitions (search, code exec, analysis)
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ .env.example         # Environment template
â””â”€â”€ README.md            # This file
```

## ğŸ”§ Core Components

### Agents Module
- **Agent**: Individual AI agent with memory and execution logging
- **AgentPool**: Manages multiple agents with different execution modes
- **SwarmOrchestrator**: High-level orchestration across multiple pools

### Graph Module
- **SwarmGraph**: LangGraph-based workflow engine
- **MemoryManager**: Dual-tier memory with categorization
- **EvaluationEngine**: Output evaluation and scoring

### Tools Module
- **web_search**: Search the internet (requires Tavily API)
- **code_execution**: Execute Python/bash code safely
- **file_operations**: Read, write, and list files
- **data_analysis**: JSON parsing and statistics
- **memory_store**: Key-value memory operations

## ğŸ¯ Use Cases

1. **Research Automation**: Parallel research from multiple agents + synthesis
2. **Content Analysis**: Multi-perspective analysis with evaluation
3. **Code Review**: Specialized agents analyzing different code aspects
4. **Data Processing**: Distributed data analysis and aggregation
5. **Customer Support**: Coordinated agents handling different support tiers

## ğŸ“Š Monitoring & Analytics

Get execution statistics:

```python
# Agent statistics
agent_stats = agent.get_execution_stats()
# Returns: executions, success rate, timing

# Pool statistics
pool_stats = pool.get_pool_stats()
# Returns: agent count, execution mode, per-agent stats

# Orchestration statistics
orchestration_stats = orchestrator.get_orchestration_stats()
# Returns: pool count, total executions, per-pool details
```

## ğŸš€ Advanced Features

### Execution Modes

- **SEQUENTIAL**: Agents execute one after another (safer, deterministic)
- **PARALLEL**: Agents execute simultaneously (faster, for independent tasks)
- **HIERARCHICAL**: Coordinator agent directs worker agents (complex workflows)

### Memory Tiers

- **Short-term**: Session-specific, auto-cleared, with TTL support
- **Long-term**: Persistent, categorized, searchable

### Evaluation Criteria

Define custom evaluation criteria:

```python
criteria = {
    "relevance": "Is it relevant to the task?",
    "completeness": "Does it cover all aspects?",
    "accuracy": "Is the information correct?"
}
evaluation = evaluator.evaluate_output(output, criteria)
```

## ğŸ”Œ Integration Patterns

### With LangChain
```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# Use SwarmForge agents within LangChain chains
chain = LLMChain(llm=llm, prompt=template)
```

### With External APIs
```python
# Tools can call any external API
@tool
def custom_api_call(query: str):
    response = requests.get(f"https://api.example.com/search?q={query}")
    return response.json()
```

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| "No LLM API key configured" | Set `OPENAI_API_KEY` or `GROQ_API_KEY` in `.env` |
| "Module not found" | Run `pip install -r requirements.txt` |
| Web search not working | Set `TAVILY_API_KEY` in `.env` |
| Rate limit errors | Add delay between requests, use Groq (free tier) |
| Memory issues | Clear short-term memory with `memory.clear_short_term()` |

## ğŸ“š Learning Resources

- [LangChain Documentation](https://python.langchain.com/)
- [LangGraph Guide](https://langchain-ai.github.io/langgraph/)
- [OpenAI API Reference](https://platform.openai.com/docs/)
- [Groq Console](https://console.groq.com/)

## ğŸ¤ Contributing

Feel free to extend SwarmForge with:
- Additional tools and integrations
- Custom execution strategies
- Advanced memory backends (Redis, Pinecone, etc.)
- Web UI dashboard
- Distributed execution support

## ğŸ“„ License

MIT License - Free to use and modify

## ğŸ“ Next Steps

1. âœ… **Run the demo**: `python main.py`
2. ğŸ“š **Read the code**: Review agents.py, graph.py, tools.py
3. ğŸ”¨ **Build your swarm**: Create custom agents and tools
4. ğŸš€ **Deploy**: Use Azure/AWS/GCP with Docker
5. ğŸ“– **Document**: Add your use cases and patterns

---

**Made with â¤ï¸ by the SwarmForge team. Happy swarming! ğŸ**
